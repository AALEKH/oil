-- Data types for the osh AST, aka "Lossless Syntax Tree".
--
-- Invariant: the source text can be reconstructed byte-for-byte from this
-- tree.
--
-- Exceptions:
-- * <<- here docs with leading tabs, since we don't want those for
--   conversion.  We don't want files with mixed tabs and spaces.
-- * Found to be not strictly necessary for oil conversion
--   * foo() { } vs function foo { } -- ksh 
--
-- The AST is composed of the builtin ASDL types (string, int, bool) and our
-- application type 'id', which is core.id_kind.Id.

-- Unrepresented:
-- * let arithmetic (rarely used)
-- * coprocesses -- one with arg and one without
-- * select block
-- * 1>&2- to close redirect
-- * case fallthrough ;& and ;;&

-- Represented but Not Parsed:
-- * ArrayPair -- ([foo]=bar)

-- Parsed but Not Implemented
-- * extended glob
-- * <> redirect

-- TODO: Preserve these source differences:
-- * order of redirects: 'echo >out.txt hi'  vs echo hi >out.txt
--   * In the printer, I want to preserve line breaks!  foo \bar?

module syntax
{
  -- core/main_loop.py
  parse_result = EmptyLine | Eof | Node(command cmd)
 
  source = 
    Interactive
  | Unused(string comment)     -- completion and history never show parse errors?
  | CFlag
  | Stdin(string comment)
    -- TODO: if it's not the main script, it's sourced, and you could provide
    -- a chain of locations back to the sourced script!
    -- MainFile(string path) or SourcedFile(string path, int spid)
  | MainFile(string path)
  | SourcedFile(string path, int spid)
  | ArgvWord(int word_spid)    -- code parsed from a single word.
                               -- e.g. trap, complete -W, printf
  | ArgvCommand(int first_spid) -- first word
  | EvalArg(int eval_spid)     -- special case for 'eval'
                               -- The rest of the args are JOINED, so it's not
                               -- clear where they come from.
  | Trap(int word_spid)        -- code for the trap builtin
  | Variable(extent assigned)  -- $PS1, $PS4, etc.
                               --   where the variable was last assigned
    -- 3 instances of reparsing:

    -- alias expansion (location of first word)
  | Alias(string argv0, int argv0_spid)

    -- reparsing in  echo `echo \"hi\"`
  | Backticks(int left_spid, int right_spid)

    -- reparsing of x+1 in a[x+1]=y
  | LValue(int left_spid, int right_spid)

  -- A temporary value that's NOT stored in the LST.  It's the beginning or end
  -- of a line_span / extent.
  position = (int line_id, int col)

  -- A line_span represents the source location of a token, which never crosses
  -- lines.  Encoded into LST with 'int spid'.
  line_span = (int line_id, int col, int length)

  -- An extent represents the source locations of a word or word_part, which
  -- may span multiple lines.  Encoded into LST with 'int exid'.
  extent = (int s_line_id, int s_col,
            int e_line_id, int e_col)

  -- Logically, here's our record for a physical line.  For compactness, we
  -- TRANSPOSE it into 3 parallel arrays, so this record is unused.
  -- line_record = (int line_num, string val, source src)

  -- NOTE: We use 'val' for execution, and the line_span from span_id for
  -- errors and translation.  (LATER: Add 'speck' and 'strand' to optimize for
  -- space.)
  token = (id id, string val, int span_id)

  bracket_op = 
    WholeArray(id op_id)  -- * or @
  | ArrayIndex(arith_expr expr)

  suffix_op = 
    StringNullary(id op_id)  -- ${x@Q}
  | StringUnary(id op_id, word arg_word)  -- e.g. ${v:-default}
    -- TODO: token for / to attribute errors
  | PatSub(word pat, word? replace, id replace_mode)
  -- begin is optional with ${array::1}
  | Slice(arith_expr? begin, arith_expr? length)

  -- TODO: Constructors should be scoped?  array_item::Pair?
  array_item = 
    ArrayWord(word w)
  | ArrayPair(word key, word value)

  word_part = 
    -- TODO: should be array_item* items.  They CAN be mixed, like a=([x]=y z)
    ArrayLiteralPart(word* words)
  | LiteralPart(token token)
    -- escaped case is separate so the evaluator doesn't have to check token ID
  | EscapedLiteralPart(token token)
    -- for 'foo=' and "${a:-}"
  | SingleQuotedPart(token left, token* tokens)
  | DoubleQuotedPart(word_part* parts)
  | SimpleVarSub(token token)
  | BracedVarSub(token token,
                id? prefix_op,  -- prefix # or ! operators
                bracket_op? bracket_op
                suffix_op? suffix_op)
    -- This should be token tilde, token rest
  | TildeSubPart(token token)
    -- For command sub and process sub: $(...)  <(...)  >(...)
  | CommandSubPart(command command_list, token left_token)
  | ArithSubPart(arith_expr anode)
    -- {a,b,c}
  | BracedTuple(word* words)
    -- {1..10} or {-5..10..2} or {01..10} (leading zeros matter)
    -- {a..f} or {a..f..2} or {a..f..-2}
  | BracedRange(id kind, string start, string end, int? step)
    -- note: optional int may need special handling in ASDL
  -- extended globs are parsed statically, unlike globs
  | ExtGlobPart(token op, word* arms)

  word = 
    -- for RHS of 'x=' and the argument in ${x:-}
    EmptyWord
  | TokenWord(token token)
    -- A CompoundWord can contain any word_part except the Braced*Part.
    -- We could model this with another variant type but it incurs runtime
    -- overhead and seems like overkill.  Note that DoubleQuotedPart can't
    -- contain a SingleQuotedPart, etc. either.
  | CompoundWord(word_part* parts)
    -- A BracedWordTree is a word because it can appear in a command.  It can
    -- contains any type of word_part.
  | BracedWordTree(word_part* parts)
    -- For dynamic parsing of test/[ -- the string is already evaluated.
  | StringWord(id id, string s)

  -- TODO: Need more tokens/spids to translate a[x++]=1
  -- These don't follow the LST design, because they're shared for
  -- s['x']+='y' and (( s[ 42 ] ++ )).
  -- It would be better runtime.lvalue were be the shared representation, and
  -- there were 2 different lhs_expr types.  They both should contribute their
  -- location information.
  lhs_expr =
    LhsName(string name)
  | LhsIndexedName(string name, arith_expr index)
  | CompatIndexedName(string name, string index)  -- for translation

  arith_expr =
    ArithVarRef(token token)  -- variable without $
  | ArithWord(word w)  -- a string that looks like an integer

  | UnaryAssign(id op_id, lhs_expr child)
  | BinaryAssign(id op_id, lhs_expr left, arith_expr right)
  | ArithUnary(id op_id, arith_expr child)
  -- TODO: add token for divide by zero
  | ArithBinary(id op_id, arith_expr left, arith_expr right)
  | TernaryOp(arith_expr cond, arith_expr true_expr, arith_expr false_expr)
  | FuncCall(arith_expr func, arith_expr* args)

  bool_expr =
    WordTest(word w)  -- e.g. [[ myword ]]
  | BoolBinary(id op_id, word left, word right)
  | BoolUnary(id op_id, word child)
  | LogicalNot(bool_expr child)
  | LogicalAnd(bool_expr left, bool_expr right)
  | LogicalOr(bool_expr left, bool_expr right)

  redir = 
    Redir(token op, int fd, word arg_word)
  | HereDoc(token op, int fd,
            word here_begin,  -- e.g. EOF or 'EOF'
            int here_end_span_id,  -- this span is an entire line
            word_part* stdin_parts -- one for each line
           )

  assign_op = Equal | PlusEqual
  assign_pair = (lhs_expr lhs, assign_op op, word? rhs, int* spids)
  env_pair = (string name, word val, int* spids)

  -- Each arm tests one word against multiple words
  case_arm = (word* pat_list, command* action, int* spids)
  if_arm = (command* cond, command* action, int* spids)

  iterable = 
    IterArgv
  | IterArray(word* words)

  -- TODO: Make field names consistent: child vs expr, etc.

  command = 
    NoOp
    -- TODO: respect order of words and redirects
  | SimpleCommand(word* words, redir* redirects, env_pair* more_env)
    -- This doesn't technically belong in the LST, but it's convenient for
    -- execution
  | ExpandedAlias(command child, redir* redirects, env_pair* more_env)
  | Sentence(command child, token terminator)
    -- TODO: Rename ShAssign
  | Assignment(id keyword, string* flags, assign_pair* pairs)
    -- TODO: add optional type_expr (only appears in var/const)
  | OilAssign(token? keyword, expr lhs, token op, expr rhs)
  | ControlFlow(token token, word? arg_word)
  | Pipeline(command* children, bool negated, int* stderr_indices)
  | AndOr(id* ops, command* children)
    -- Part of for/while/until.
  | DoGroup(command* children, redir* redirects)
    -- A brace group is a compound command, with redirects.
  | BraceGroup(command* children, redir* redirects)
    -- Contains a single child, like CommandSubPart
  | Subshell(command command_list, redir* redirects)
  | DParen(arith_expr child, redir* redirects)
  | DBracket(bool_expr expr, redir* redirects)
    -- do_arg_iter: whether to implicitly loop over "$@"
    -- TODO: Make iter_words a sum type.  iterable for_words
  | ForEach(string iter_name, word* iter_words, bool do_arg_iter,
            command body, redir* redirects)
    -- C-style for loop.  Any of the 3 expressions can be omitted.
    -- TODO: body is required, but only optional here because of initialization
    -- order.
  | ForExpr(arith_expr? init, arith_expr? cond, arith_expr? update,
            command? body, redir* redirects)
  | WhileUntil(token keyword, command* cond, command body, redir* redirects)
  | If(if_arm* arms, command* else_action, redir* redirects)
  | Case(word to_match, case_arm* arms, redir* redirects)
  | FuncDef(string name, command body, redir* redirects)
  | TimeBlock(command pipeline)
    -- Most nodes optimize it out as command*, but there are a few places where
    -- this is useful for type safety.
  | CommandList(command* children)

  -- For now, using stderr_indices representation because it's more compact.
  -- |& in osh; |- in oil.
  -- pipe_op = Pipe | PipeAndStderr

  -- Glob representation, for converting ${x//} to extended regexes.

  -- Example: *.[ch] is:
  --   GlobOp(<Glob_Star '*'>),
  --   GlobLit(Glob_OtherLiteral, '.'),
  --   CharClass(False, ['ch'])  # from Glob_CleanLiterals token

  glob_part =
    GlobLit(id id, string s)
  | GlobOp(id op_id)  -- * or ?
  | CharClass(bool negated, string* strs)

  -- Char classes are opaque for now.  If we ever need them:
  -- * Collating symbols are [. .]
  -- * Equivalence classes are [=

  printf_part =
    Literal(token token)
    -- flags are 0 hyphen space + #
    -- type is 's' for %s, etc.
  | Percent(token? flag, token? width, token? precision, token type)

  --
  -- OIL LANGUAGE
  --

  -- NOTE: These are defined in the same ASDL module since the OSH LST will
  -- contain oil_command, e.g. for 'var', 'func', etc.

  regex = 
    Var(token name)
  | SingleQuoted
  | DoubleQuoted
  | Repeat(token op, regex child)  -- + * ?
  | RepeatRange(token min, token max, regex child)  -- x^{1,2}
  | Concat(regex* parts)

  expr =
    Var(token name)  -- a variable name to evaluate
    -- words can look like "$foo" or '1' or '3.14159' or '1e-19'
    -- also note that ArrayLiterals could appear in command mode.
    -- echo @[a b c]
  | Const(token c)   -- could be integer, or false, etc.
  | ArrayLiteral(token left, word* items)  -- a variable name to evaluate
  | RegexLiteral(token left, regex regex)

    -- These are duplicated as "parts" too
  | VarSub(token left, expr e)  -- might be a variant for ${x %02d}
  | CommandSub(token left, command cmd)
  | ExprSub(token left, expr  e)
  | SingleQuoted(token left, token* tokens)
  | DoubleQuoted(token left, oil_word_part* parts)

  | Unary(token op, expr child)
  | Binary(token op, expr left, expr right)
  | FuncCall(expr func, expr* args)
    -- a[1, 2] or a[1:2]
    -- should 1:2 be an expression then?
  | Subscript(expr collection, expr* indices)

  -- COPIED from Python-3.7/Parser/Python.asdl and lightly modified.
  -- Will need more changes.

  | IfExp(expr test, expr body, expr orelse)
  | Dict(expr* keys, expr* values)
  | Set(expr* elts)
  | ListComp(expr elt, comprehension* generators)
  | SetComp(expr elt, comprehension* generators)
  | DictComp(expr key, expr value, comprehension* generators)
  | GeneratorExp(expr elt, comprehension* generators)
  -- need sequences for compare to distinguish between
  -- x < 4 < 3 and (x < 4) < 3 (NOTE: unused; Oil currently uses Binary)
  | Compare(expr left, cmpop* ops, expr* comparators)
  | Call(expr func, expr* args, keyword* keywords)
  | Num(int n) -- do we need this for Oil?
  | Str(string s) -- need to specify raw, unicode, etc?
  | FormattedValue(expr value, int? conversion, expr? format_spec)
  | JoinedStr(expr* values)
  | Ellipsis -- do we need this?

  -- the following expressions can appear in assignment context
  | Attribute(expr value, token attr, expr_context ctx)
    -- TODO: we used Subscript() above, might want to migrate?
  | Subscript_PYTHON(expr value, slice slice, expr_context ctx)
  | Starred(expr value, expr_context ctx)
  | Name(token identifier, expr_context ctx)
  | List(expr* elts, expr_context ctx)
  | Tuple(expr* elts, expr_context ctx)

  expr_context = Load | Store | Del | AugLoad | AugStore | Param

  slice = Slice(expr? lower, expr? upper, expr? step)
        | ExtSlice(slice* dims)
        | Index(expr value)

  comprehension = (expr target, expr iter, expr* ifs, int is_async)

  cmpop = Eq | NotEq | Lt | LtE | Gt | GtE | Is | IsNot | In | NotIn

  -- keyword arguments supplied to call (NULL identifier for **kwargs)
  keyword = (token? arg, expr value)


  -- NOTE: Remove these for the first cut?  We could mostly reuse OSH nodes.
  -- And then we can share the evaluator to have identical semantics?

  oil_word_part = 
    Literal(token token)
    -- for 'foo=' and "${a:-}"
  | SingleQuoted(token left, token* tokens)
  | DoubleQuoted(token left, oil_word_part* parts)
  | TildeSub(token token)
  | VarSub(token token)
  | ExprSub(token token,
            id? prefix_op,  -- prefix # or ! operators
            bracket_op? bracket_op
            suffix_op? suffix_op)
  | CommandSub(oil_cmd command_list, token left_token)

  -- NOTE differences from OSH: no TokenWord, but add GlobWord, etc.
  oil_word = 
    Compound(oil_word_part* parts)
  | Glob()
  | Braced(oil_word_part* parts) -- TODO: Does it need its own parts?

  oil_cmd = 
    -- TODO: respect order of words and redirects
    Simple(oil_word* words, redir* redirects, env_pair* more_env)
  | Sentence(oil_cmd child, token terminator)
  | Pipeline(oil_cmd* children, bool negated)
  | AndOr(id* ops, oil_cmd* children)
  | CommandList(oil_cmd* children)
}
